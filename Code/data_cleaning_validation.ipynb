{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jw/9mhjkj2530q0dcv2dbdg1zmm0000gn/T/ipykernel_47406/739861301.py:2: DtypeWarning: Columns (3,4,5,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  reddit_comments = pd.read_csv(\"/Users/npop/Code/Projects/ML7641_Project/Official_Datasets/reddit_comments.csv\")\n"
     ]
    }
   ],
   "source": [
    "full_movie_data = pd.read_csv(\"/Users/npop/Code/Projects/ML7641_Project/Official_Datasets/full_movie_data.csv\")\n",
    "reddit_comments = pd.read_csv(\"/Users/npop/Code/Projects/ML7641_Project/Official_Datasets/reddit_comments.csv\")\n",
    "youtube_comments = pd.read_csv(\"/Users/npop/Code/Projects/ML7641_Project/Official_Datasets/youtube_comments.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Valid Reddit Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_comments.drop_duplicates(subset=['body', 'post_date'], inplace=True)\n",
    "reddit_comments.dropna(subset=['post_date'], inplace=True)\n",
    "reddit_comments.reset_index(drop=True, inplace=True)\n",
    "full_movie_data.drop_duplicates(subset=['post_id'], inplace=True)\n",
    "full_movie_data = full_movie_data[full_movie_data['Match'] == 1].copy(deep=True)\n",
    "reddit_comments_v = reddit_comments[reddit_comments['post_id'].isin(full_movie_data['post_id'])].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_comments_v['movie_title'] = \"Not Set\"\n",
    "reddit_comments_v['movie_release_date'] = \"Not Set\"\n",
    "reddit_comments_v['movie_actors'] = \"Not Set\"\n",
    "reddit_comments_v.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_movie_info() -> None:\n",
    "    for post_id in reddit_comments_v['post_id'].unique():\n",
    "        movie_entry = full_movie_data[full_movie_data['post_id'].str.contains(post_id)]\n",
    "        title = movie_entry['title'].values[0]\n",
    "        release_date = movie_entry['release_date'].values[0]\n",
    "        actors = movie_entry['Actors'].values[0]\n",
    "        subset_filter = reddit_comments_v['post_id'].str.contains(post_id)\n",
    "        reddit_comments_v.loc[subset_filter, \"movie_title\"] = title\n",
    "        reddit_comments_v.loc[subset_filter, \"movie_release_date\"] = release_date\n",
    "        reddit_comments_v.loc[subset_filter, \"movie_actors\"] = actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set_movie_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_comments_v['post_date'] = pd.to_datetime(reddit_comments_v['post_date'])\n",
    "reddit_comments_v['movie_release_date'] = pd.to_datetime(reddit_comments_v['movie_release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_comments_v.dropna(subset=['movie_title'], inplace=True)\n",
    "reddit_comments_v.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we only want comments posted before the movie release date:\n",
    "reddit_comments_v[\"valid_post_date\"] = reddit_comments_v['post_date'] < reddit_comments_v['movie_release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_comments_v[reddit_comments_v['valid_post_date'] == True].to_csv(\"/Users/npop/Code/Projects/ML7641_Project/Official_Datasets/stage_2/reddit_comments_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_movie_data.to_csv(\"/Users/npop/Code/Projects/ML7641_Project/Official_Datasets/stage_2/movie_data_valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Valid YouTube Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_comments = pd.read_csv(\"/Users/npop/Code/Projects/ML7641_Project/Official_Datasets/youtube_comments.csv\")\n",
    "youtube_videos = pd.read_csv(\"/Users/npop/Code/Projects/ML7641_Project/Official_Datasets/youtube_videos.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_comments.drop_duplicates(subset=['comment_text', 'comment_date'], inplace=True)\n",
    "youtube_comments.dropna(subset=['comment_date'], inplace=True)\n",
    "youtube_comments.dropna(subset=['comment_text'], inplace=True)\n",
    "youtube_comments.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_yt_link(text) -> bool:\n",
    "    if type(text) != str:\n",
    "        return False\n",
    "    elif \"youtu\" in text:\n",
    "        return True\n",
    "\n",
    "def extract_youtube_id(url:str) -> str:\n",
    "    \"\"\"Extract the youtube video id from a youtube url\n",
    "    \n",
    "    Args:\n",
    "        url (str): youtube url\n",
    "\n",
    "    Returns:\n",
    "        str: youtube video id\n",
    "    \"\"\"\n",
    "    import re\n",
    "    if not has_yt_link(url):\n",
    "        print(\"Not a youtube link\")\n",
    "        return \"\"\n",
    "    if \"youtube\" in url:\n",
    "        match = re.search(r\"(?<=v=)[a-zA-Z0-9_-]+\", url)\n",
    "        if match:\n",
    "            return match.group(0)\n",
    "    elif \"youtu.be\" in url:\n",
    "        match = re.search(r\"(?<=youtu.be/)[a-zA-Z0-9_-]+\", url)\n",
    "        if match:\n",
    "            return match.group(0)\n",
    "    else:\n",
    "        print(\"Not a youtube link\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_movie_data['yt_vid_id'] = full_movie_data['post_url_x'].apply(extract_youtube_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_yt_ids = full_movie_data['yt_vid_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_comments_v = youtube_comments[youtube_comments['video_id'].isin(valid_yt_ids)].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_comments_v.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_comments_v['movie_title'] = \"Not Set\"\n",
    "youtube_comments_v['movie_release_date'] = \"Not Set\"\n",
    "youtube_comments_v['movie_actors'] = \"Not Set\"\n",
    "youtube_comments_v.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_meta_to_yt_comments() -> None:\n",
    "    for video_id in youtube_comments_v['video_id'].unique():\n",
    "        movie_entry = full_movie_data[full_movie_data['yt_vid_id'].str.contains(video_id)]\n",
    "        # Extract the movie information from full_movie_data\n",
    "        title = movie_entry['title'].values[0]\n",
    "        release_date = movie_entry['release_date'].values[0]\n",
    "        actors = movie_entry['Actors'].values[0]\n",
    "        # Update the comments dataframe only for the comments related to the current movie\n",
    "        subset_filter = youtube_comments_v['video_id'].str.contains(video_id)\n",
    "        youtube_comments_v.loc[subset_filter, \"movie_title\"] = title\n",
    "        youtube_comments_v.loc[subset_filter, \"movie_release_date\"] = release_date\n",
    "        youtube_comments_v.loc[subset_filter, \"movie_actors\"] = actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_movie_data['yt_vid_id'].fillna(\"No Link\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_meta_to_yt_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_comments_v['comment_date'] = pd.to_datetime(youtube_comments_v['comment_date']).dt.date\n",
    "youtube_comments_v['movie_release_date'] = pd.to_datetime(youtube_comments_v['movie_release_date']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"/Users/npop/Code/Projects/ML7641_Project/Official_Datasets/stage_2/youtube_comments_valid.csv\"\n",
    "youtube_comments_v[youtube_comments_v['comment_date'] < youtube_comments_v['movie_release_date']].to_csv(p, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
